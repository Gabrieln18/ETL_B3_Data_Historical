{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "05c83fa2-222c-4d03-afd2-560f06c55699",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Mini projeto de ETL para consumo de dados históricos da B3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce85e365-58aa-42ef-8c0b-a5c8de191b81",
   "metadata": {},
   "source": [
    "# Extraction Data\n",
    "\n",
    "O arquivo com os dados históricos da B3 não possui delimitações (|,:, ;, etc). Na verdade ele é um arquivo posicional, ou seja, ele possui uma string gigantesca com os dados da série da bovespa.\n",
    "\n",
    "Para poder manusear estes dados, é necessário ter um documento para entender com funciona sua estrutura, sendo assim, a bolsa de valores B3 disponibiliza um documento em PDF chamado `SeriesHistoricas_Layout.pdf`.\n",
    "\n",
    "Link Series Históricas Layout PDF: https://www.b3.com.br/data/files/C8/F3/08/B4/297BE410F816C9E492D828A8/SeriesHistoricas_Layout.pdf\n",
    "\n",
    "O arquivo COTAHIST.AAAA.TXT contém as informações das cotações históricas relativas à negociação de todos os papéis-mercado no período de um ano, classificado pelos campos Tipo de registro, Data do pregão, Código de BDI, Nome da empresa e Código de Negociação. Esta divisão não impede que o usuário o classifique de acordo com as suas necessidades, segundo o equipamento e software a serem usados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "1f28ffd2-5466-4e1d-837f-fa2744bcb4bd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# importing the libraries\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "5a7278ac-e51f-4abb-9c92-10bc80d277dc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# LAYOUT\n",
    "# DATA_DO_PREGAO = 2 - 10\n",
    "# CODIGO_DO_BDI = 10 - 12\n",
    "# CODIGO_DO_PAPEL = 12 - 24\n",
    "# NOME_DA_ACAO = 27 - 39\n",
    "# PRECO_DE_ABERTURA = 56 - 69\n",
    "# PRECO_MAXIMO = 69 - 82\n",
    "# PRECO_MINIMO = 82 - 95\n",
    "# PRECO_FECHAMENTO = 108 - 121\n",
    "\n",
    "def read_files(path, name_file, year_date, type_file):\n",
    "    \n",
    "    _file = f\"{path}/{name_file}{year_date}.{type_file}\"\n",
    "\n",
    "    colspecs = [(2,10),\n",
    "                (10,12),\n",
    "                (12,24),\n",
    "                (27,39),\n",
    "                (56,69),\n",
    "                (69,82),\n",
    "                (82,95),\n",
    "                (108,121),\n",
    "                (152,170),\n",
    "                (170,188)\n",
    "               ]\n",
    "\n",
    "    # column names\n",
    "    names = [\"data_pregao\", \"codbdi\", \"sigla_acao\", \"nome_acao\", \"preco_abertura\", \"preco_maximo\", \"preco_minimo\", \"preco_fechamento\",\n",
    "            \"qtd_negocios\", \"volume_negocios\"]\n",
    "\n",
    "    dataframe = pd.read_fwf(_file, colspecs = colspecs, names = names, skiprows=1)\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1812b9a-4e7f-43b3-a151-23a3d80957ed",
   "metadata": {},
   "source": [
    "# Transformation Data\n",
    "\n",
    "Ao visualizar a estrutura dos dados, precisamos formatar alguns e descartar outros. Neste caso, segue a lista de campos que precisam passar por uma transformação em suas estruturas:\n",
    "\n",
    "`data_pregao` = precisa estar formatado em tipo `datetime` <br>\n",
    "`preco_max` = precisa estar em formato `float` <br>\n",
    "`preco_min` = precisa estar em formato `float` <br>\n",
    "`preco_fechamento` = precisa estar em formato `float` <br>\n",
    "`preco_abertura` = precisa estar em formato `float` <br>\n",
    "\n",
    "Ademais, estabelecer o lote padrão igual a 2 (neste caso o codbdi igual a 2), descartando os outros lotes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "11e81fc9-ecb3-4781-9f37-4beb42c82751",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# filtering stocks\n",
    "\n",
    "def filter_stocks(dataframe, ):\n",
    "    # filtering lots equal to 2\n",
    "    dataframe = dataframe[dataframe['codbdi'] == 2]\n",
    "    # discarding the codbdi column, it will no longer be necessary\n",
    "    dataframe = dataframe.drop(['codbdi'], axis=1)\n",
    "    return dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "a364c2e8-59dd-404d-b7ee-dd376895ed9d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# adjusting date field\n",
    "\n",
    "def parse_date(dataframe):\n",
    "    dataframe['data_pregao'] = pd.to_datetime(dataframe['data_pregao'], format=\"%Y%m%d\")\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "f25d318c-7de6-427f-b2c1-5e65a48c42c5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# adjustment of numeric fields\n",
    "\n",
    "def parse_values(dataframe):\n",
    "    dataframe['preco_abertura'] = (dataframe['preco_abertura'] / 100).astype(float)\n",
    "    dataframe['preco_maximo'] = (dataframe['preco_maximo'] / 100).astype(float)\n",
    "    dataframe['preco_minimo'] = (dataframe['preco_minimo'] / 100).astype(float)\n",
    "    dataframe['preco_fechamento'] = (dataframe['preco_fechamento'] / 100).astype(float)\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "979b1750-6a8f-497c-9ec4-c242ffba2390",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Load Data\n",
    "\n",
    "Finalmente, inicia o processo de carregar estes dados uma vez tratados durante o o pipeline. Neste caso, foi feito o uso de uma automação que executa todos os processos da ETL em uma sequência assíncrona. \n",
    "\n",
    "Por final, salvamos os dados em um arquivo do tipo `.csv` - chamado de `all_bovespa`. Disponibilizando uma estrutura automatizada para consumo de dados tratados para analistas e cientistas de dados em um equipe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "11f54fb0-3d38-4d34-9fdf-9f839aed5d64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenating the files\n",
    "\n",
    "# If the user wants to pull several historical series from B3 (because the historical data starts from 1986),\n",
    "# they can iterate several files and go through ETL processing automatically.\n",
    "\n",
    "def concat_files(path, name_file, year_date, type_file, final_file):\n",
    "    \n",
    "    for i, y in enumerate(year_date):\n",
    "        # Processing steps (filtering, parsing dates, parsing float values)\n",
    "        dataframe = read_files(path, name_file, y, type_file)\n",
    "        dataframe = filter_stocks(dataframe)\n",
    "        dataframe = parse_date(dataframe)\n",
    "        dataframe = parse_values(dataframe)\n",
    "        \n",
    "        if i == 0:\n",
    "            dataframe_final = dataframe\n",
    "        else:\n",
    "            dataframe_final = pd.concat([dataframe_final, dataframe])\n",
    "            \n",
    "    dataframe_final.to_csv(f'{path}/{final_file}', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "22e91ddb-f9ee-43d1-921a-ac0fa486155b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Running ETL program\n",
    "\n",
    "# list of years (files you have)\n",
    "year_date_list = ['2024']\n",
    "# file path where the downloaded files are located\n",
    "path = \"/home/gabriel/Documentos/Jupyter Notebooks\"\n",
    "name_file = \"COTAHIST_A\"\n",
    "type_file = \"TXT\"\n",
    "# final file name\n",
    "final_file = \"all_bovespa.csv\"\n",
    "\n",
    "concat_files(path, name_file, year_date_list, type_file, final_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
